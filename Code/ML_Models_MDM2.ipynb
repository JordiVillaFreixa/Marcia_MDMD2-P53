{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47d5ebb3-c18a-4ef8-be5e-3df3f7dbafe8",
   "metadata": {},
   "source": [
    "### Machine Learning Models for Training and Testing in the Identification of MDM2-P53 Inhibitors ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a24e654-a998-49a2-8b1a-ed793aa3aa00",
   "metadata": {},
   "source": [
    "This Jupyter notebook helps users develop and evaluate machine-learning models for structure-based virtual screening, specifically targeting MDM2 at the p53 binding site. The models are classification-based and can be trained with or without hyperparameter tuning and cross-validation. Users can select either PLEC or GRID features for their analysis.\n",
    "\n",
    "This methodology and code are based on the Nature Protocols paper: Tran-Nguyen, V. K., Junaid, M., Simeon, S., & Ballester, P. J. (2023). A practical guide to machine-learning scoring for structure-based virtual screening. We have made some changes to hyperparameter optimization and added cross-validation for each model.\n",
    "\n",
    "Before running the notebook, we suggest configuring the protocol-env environment. This can be done using the protocol-env.yml file available in the https://github.com/vktrannguyen/MLSF-protocol."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de05aa3c-eb26-4e79-b9d5-a1dae8dc8f00",
   "metadata": {},
   "source": [
    "# Import python dependencies #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ee93b4-6b22-4c86-b4ae-42ccc4932009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import oddt\n",
    "import oddt.pandas as opd\n",
    "from oddt.pandas import ChemDataFrame\n",
    "from oddt.fingerprints import PLEC\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import tempfile\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import matthews_corrcoef, precision_recall_curve, accuracy_score, auc\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils import parallel_backend\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import deepchem as dc\n",
    "from deepchem.utils import download_url, load_from_disk\n",
    "from deepchem.utils.vina_utils import prepare_inputs\n",
    "from deepchem.models import AtomicConvModel\n",
    "from deepchem.feat import RdkitGridFeaturizer\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers, regularizers\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import Adadelta, Adam, RMSprop\n",
    "import hyperopt\n",
    "from hyperopt import hp, tpe, Trials, fmin, STATUS_OK, space_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc2f8bb-2745-418e-8b86-168ca88528e5",
   "metadata": {},
   "source": [
    "# Data training and test set #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2167e05d-d2bc-4fa3-8e7b-581308f7c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide the pathway to the csv training data file:\n",
    "train_data = pd.read_csv(\"Provide_the_pathway_to_your_csv_training_data_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a6ecf7-5d8a-48d0-ac5d-f9ff7b7e772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call the \"activity\" labels of all training and test molecules:\n",
    "Train_Class = train_data['activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d8a640-b940-488f-a802-4eb2a52a18c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide the pathway to the csv test data file:\n",
    "test_data = pd.read_csv(\"Provide_the_pathway_to_your_csv_test_data_file\")\n",
    "\n",
    "#Call the \"activity\" labels of all training and test molecules:\n",
    "Test_Class = test_data['activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74c682f-066a-40d8-87f9-a4d636d57e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide the pathway to the training molecules (mol2 or multi-mol2):\n",
    "train_mol2 = opd.read_mol2(\"Provide_the_pathway_to_the_training_molecule\")\n",
    "train_mol2.columns = ['mol', 'mol_name']\n",
    "train = train_mol2.merge(train_data.drop_duplicates(subset = ['mol_name']), how = 'left', on = 'mol_name')\n",
    "train_mols = train['mol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae6e594-ed17-4b4b-ac42-aa5298923069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide the pathway to the test molecules (mol2 or multi-mol2):\n",
    "test_mol2 = opd.read_mol2(\"Provide_the pathway_to_the_test_molecules\")\n",
    "test_mol2.columns = ['mol', 'mol_name']\n",
    "test = test_mol2.merge(test_data.drop_duplicates(subset = ['mol_name']), how = 'left', on = 'mol_name')\n",
    "test_mols = test['mol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09c2462-11f9-489b-adaf-0668fcc6a646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide the pathway(s) to the training and set target/receptor structure(s):\n",
    "receptor_train = next(oddt.toolkit.readfile('mol2', 'Provide_the_pathway_to_your_training_receptor_mol2_file'))\n",
    "receptor_test = next(oddt.toolkit.readfile('mol2', 'Provide_the_pathway_to_your_test_receptor_mol2_file'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb08ecb-cdda-4c3e-9b1d-70cf63856e21",
   "metadata": {},
   "source": [
    "## Function to obtain PLEC fingerprints for training and test set molecules using the same receptor ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b163b1ee-8d76-44ea-9fd0-ce238c79cabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Users may keep only one of the following two functions if the training target/receptor structure is the same as the test target/receptor structure\n",
    "#Users may change the parameters (size, depth_protein, depth_ligand, distance_cutoff) if they wish\n",
    "def parallel_plec_train(mol):\n",
    "    feature = PLEC(mol, protein = receptor_train, size = 4092, \n",
    "                   depth_protein = 4, depth_ligand = 2,\n",
    "                   distance_cutoff = 4.5, sparse = False)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a890f5da-f54c-43cc-a4fc-dec5b30c0820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_plec_test(mol):\n",
    "    feature = PLEC(mol, protein = receptor_test, size = 4092, \n",
    "                   depth_protein = 4, depth_ligand = 2,\n",
    "                   distance_cutoff = 4.5, sparse = False)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ef8e7d-42fe-4fcb-8f64-865b864f7c8d",
   "metadata": {},
   "source": [
    "## Run the function to compute PLEC ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325a700e-7b66-4101-86bb-850f104bc58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Users may choose another number of cores (num_cores) that corresponds to their computing resources\n",
    "num_cores = 16\n",
    "train_features = Parallel(n_jobs = num_cores, backend = \"multiprocessing\")(delayed(parallel_plec_train)(mol) for mol in tqdm(train_mols))\n",
    "test_features = Parallel(n_jobs = num_cores, backend = \"multiprocessing\")(delayed(parallel_plec_test)(mol) for mol in tqdm(test_mols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374557b8-bf29-4cbf-9985-18379aee35b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for identifying [i] if Test_Class has Nan (caution)\n",
    "nan_indices = [i for i, value in enumerate(Test_Class) if pd.isna(value)]\n",
    "\n",
    "# Imprimir los valores NaN en Test_Class\n",
    "print(\"Índices con NaN en Test_Class:\", nan_indices)\n",
    "\n",
    "# Imprimir los valores correspondientes\n",
    "print(\"Valores NaN en Test_Class:\")\n",
    "for i in nan_indices:\n",
    "    print(f\"Índice {i}: {Test_Class[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3fa53a-6838-445a-a255-801fee4795b8",
   "metadata": {},
   "source": [
    "## Training and Testing of ML Models Without Optimization but With Cross-Validation ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b07e4c7-665c-48b0-ac85-569d3ffef159",
   "metadata": {},
   "source": [
    "## SVM ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8a36a7-8a74-4a68-93f9-a8680550bc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert classes to numerical format\n",
    "Activity_Dict = {\"Active\": 1, \"Inactive\": 0}\n",
    "y_train = np.array([Activity_Dict[item] for item in Train_Class]).flatten()  # Ensure it's a one-dimensional array\n",
    "y_test = np.array([Activity_Dict[item] for item in Test_Class]).flatten()    # Ensure it's a one-dimensional array\n",
    "\n",
    "train_features_array = np.array(train_features)\n",
    "test_features_array = np.array(test_features)\n",
    "\n",
    "# Cross-validation configuration (5 folds)\n",
    "k_folds = 5\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# List to store AUC scores per fold\n",
    "auc_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_features_array, y_train)):\n",
    "    print(f\"Training fold {fold+1}/{k_folds}...\")\n",
    "\n",
    "    X_train_fold, X_val_fold = train_features_array[train_idx], train_features_array[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    # Define SVM model\n",
    "    svm_plec = SVC(degree=3, kernel=\"rbf\", probability=True)\n",
    "\n",
    "    # Train model on this fold\n",
    "    svm_plec.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_val_pred_prob = svm_plec.predict_proba(X_val_fold)[:, 1]  # Probability of the positive class\n",
    "    auc_val = roc_auc_score(y_val_fold, y_val_pred_prob)\n",
    "    auc_scores.append(auc_val)\n",
    "\n",
    "    print(f\"Fold {fold+1}: AUC = {auc_val:.4f}\")\n",
    "\n",
    "# Save cross-validation results to CSV\n",
    "auc_cv_filename = \"Provide_the_pathway_to_your_SVM-CrossValidation-AUC.csv\"\n",
    "auc_cv_df = pd.DataFrame({\"Fold\": range(1, k_folds+1), \"AUC\": auc_scores})\n",
    "auc_cv_df.loc[\"Mean\"] = [\"Mean\", np.mean(auc_scores)]\n",
    "auc_cv_df.loc[\"Std\"] = [\"Std\", np.std(auc_scores)]\n",
    "auc_cv_df.to_csv(auc_cv_filename, index=False)\n",
    "\n",
    "print(f\"Cross-validation results saved to {auc_cv_filename}\")\n",
    "\n",
    "# Train final model on the entire training dataset\n",
    "svm_plec.fit(train_features_array, y_train)\n",
    "\n",
    "# Test set evaluation\n",
    "prediction_test_svm_plec_class = svm_plec.predict(test_features_array)\n",
    "prediction_test_svm_plec_prob = svm_plec.predict_proba(test_features_array)\n",
    "\n",
    "# Compute and save test AUC\n",
    "auc_test = roc_auc_score(y_test, prediction_test_svm_plec_prob[:, 1])  # Use probability of positive class\n",
    "auc_test_filename = \"Provide_the_pathway_to_your_SVM-Test-AUC.csv\"\n",
    "pd.DataFrame({\"AUC\": [auc_test]}).to_csv(auc_test_filename, index=False)\n",
    "\n",
    "print(f\"Test set AUC: {auc_test:.4f}\")\n",
    "print(f\"Test AUC file saved as {auc_test_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa85889a-c158-43b9-91b7-6d9e08470e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that Test_Class, prediction_test_svm_plec_class, and prediction_test_svm_plec_prob exist\n",
    "if 'Test_Class' not in locals() or 'prediction_test_svm_plec_class' not in locals() or 'prediction_test_svm_plec_prob' not in locals():\n",
    "    raise ValueError(\"The variables Test_Class, prediction_test_svm_plec_class, or prediction_test_svm_plec_prob are not defined.\")\n",
    "\n",
    "# Define the log file name\n",
    "log_filename = \"Provide_the_pathway_to_your_output_log_SVM.txt\"\n",
    "\n",
    "# Ensure that the OTS directory exists\n",
    "os.makedirs(\"Provide_the_pathway_to_your_directory_where_you_save_model\", exist_ok=True)\n",
    "\n",
    "# Open the file to write the output\n",
    "with open(log_filename, \"w\") as f:\n",
    "    try:\n",
    "        # Verify sizes\n",
    "        f.write(f\"Size of Test_Class: {len(Test_Class)}\\n\")\n",
    "        f.write(f\"Size of prediction_test_svm_plec_class: {len(prediction_test_svm_plec_class)}\\n\")\n",
    "\n",
    "        # Verify contents of Test_Class\n",
    "        f.write(f\"Full content of Test_Class:\\n{Test_Class}\\n\")\n",
    "\n",
    "        # Create a DataFrame with virtual screening results\n",
    "        plec_result_svm = pd.DataFrame({\n",
    "            \"Active_Prob\": prediction_test_svm_plec_prob[:, 1],\n",
    "            \"Inactive_Prob\": prediction_test_svm_plec_prob[:, 0],\n",
    "            \"Predicted_Class\": prediction_test_svm_plec_class,\n",
    "            \"Real_Class\": Test_Class\n",
    "        })\n",
    "\n",
    "        # Verify DataFrame before saving\n",
    "        f.write(f\"First rows of plec_result_svm:\\n{plec_result_svm.head()}\\n\")\n",
    "\n",
    "        # Save DataFrame to CSV\n",
    "        csv_filename = \"Provide_the_pathway_to_your_SVM_run#.csv\"\n",
    "        plec_result_svm.to_csv(csv_filename, index=False)\n",
    "        f.write(f\"CSV file saved as {csv_filename}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cc4b0d-d4a6-41df-95eb-4e302dd564bb",
   "metadata": {},
   "source": [
    "## RF ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c23251-1182-4cff-abca-bf1c48e27221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the RF model on the training molecules:\n",
    "rf_plec = RandomForestClassifier(n_estimators = 200, max_depth=20, max_features = 'sqrt',  n_jobs = 30)\n",
    "rf_plec.fit(train_features, Train_Class)\n",
    "\n",
    "#Test the RF model on the test molecules:\n",
    "prediction_test_rf_plec_class = rf_plec.predict(test_features)\n",
    "prediction_test_rf_plec_prob = rf_plec.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d054ca73-250c-492a-b3a9-0518c16d3c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "scores = cross_val_score(rf_plec, train_features, Train_Class, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "cv_results = pd.DataFrame({\n",
    "    'Fold': [f'Fold {i+1}' for i in range(len(scores))],\n",
    "    'AUC': scores\n",
    "})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "cv_results.to_csv(\"Provide_the_pathway_to_your_cross_validation_RF_results.csv\", index=False)\n",
    "\n",
    "# Print the results\n",
    "print(f\"AUC Cross-Validation: {scores.mean()} ± {scores.std()}\")\n",
    "\n",
    "# Define the log file name\n",
    "log_filename = \"Provide_the_pathway_to_your_output_log.txt\"\n",
    "\n",
    "# Open the file to write the output\n",
    "with open(log_filename, \"w\") as f:\n",
    "    # Verify sizes\n",
    "    f.write(f\"Size of Test_Class: {len(Test_Class)}\\n\")\n",
    "    f.write(f\"Size of prediction_test_rf_plec_class: {len(prediction_test_rf_plec_class)}\\n\")\n",
    "    \n",
    "    # Verify contents of Test_Class\n",
    "    f.write(f\"Full content of Test_Class:\\n{Test_Class}\\n\")\n",
    "\n",
    "    # Create DataFrame with virtual screening results\n",
    "    plec_result_rf = pd.DataFrame({\n",
    "        \"Active_Prob\": prediction_test_rf_plec_prob[:, 0],\n",
    "        \"Inactive_Prob\": prediction_test_rf_plec_prob[:, 1],\n",
    "        \"Predicted_Class\": prediction_test_rf_plec_class,\n",
    "        \"Real_Class\": Test_Class\n",
    "    })\n",
    "\n",
    "    # Verify DataFrame before saving\n",
    "    f.write(f\"First rows of plec_result_rf:\\n{plec_result_rf.head()}\\n\")\n",
    "\n",
    "    # Save to CSV\n",
    "    os.makedirs(\"Provide_the_pathway_to_your_file_where_save_results\", exist_ok=True)  # Ensure the OTS directory exists\n",
    "    csv_filename = \"Provide_the_pathway_to_your_file_where_save_results_RF_run#.csv\"\n",
    "    plec_result_rf.to_csv(csv_filename, index=False)\n",
    "    f.write(f\"CSV file saved as {csv_filename}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06593e49-16ce-4432-b03d-a63e3cc0642f",
   "metadata": {},
   "source": [
    "## XGB ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887d3aa5-a70f-433c-a049-70d13056374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the XGB model on the training molecules:\n",
    "xgb_plec = XGBClassifier(n_jobs = 40)\n",
    "xgb_plec.fit(np.array(train_features), Train_Class)\n",
    "\n",
    "#Test the XGB model on the test molecules:\n",
    "prediction_test_xgb_plec_class = xgb_plec.predict(np.array(test_features))\n",
    "prediction_test_xgb_plec_prob = xgb_plec.predict_proba(np.array(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd077e4-5349-4f74-8eae-a0165682b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation evaluation\n",
    "cv_scores = cross_val_score(xgb_plec, np.array(train_features), Train_Class, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Print the result\n",
    "print(f\"Cross-validation AUC: {cv_scores.mean()} ± {cv_scores.std()}\")\n",
    "\n",
    "# Save the cross-validation results to a CSV file\n",
    "cv_results = pd.DataFrame({\n",
    "    'Fold': range(1, 6),\n",
    "    'AUC': cv_scores\n",
    "})\n",
    "\n",
    "cv_results.to_csv(\"Provide_the_pathway_to_your_xgb_cross_validation_results.csv\", index=False)\n",
    "\n",
    "print(\"The cross-validation results have been saved in 'Provide_the_pathway_to_your_xgb_cross_validation_results.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3a07c1-9d9c-42de-85d7-76d7ed30522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify sizes\n",
    "f.write(f\"Size of Test_Class: {len(Test_Class)}\\n\")\n",
    "f.write(f\"Size of prediction_test_xgb_plec_class: {len(prediction_test_xgb_plec_class)}\\n\")\n",
    "\n",
    "# Verify content of Test_Class\n",
    "f.write(f\"Full content of Test_Class:\\n{Test_Class}\\n\")\n",
    "\n",
    "# Create DataFrame from virtual screening results of XGB\n",
    "plec_result_xgb = pd.DataFrame({\n",
    "    \"Active_Prob\": prediction_test_xgb_plec_prob[:, 0],\n",
    "    \"Inactive_Prob\": prediction_test_xgb_plec_prob[:, 1],\n",
    "    \"Predicted_Class\": prediction_test_xgb_plec_class,\n",
    "    \"Real_Class\": Test_Class\n",
    "})\n",
    "\n",
    "# Verify DataFrame before saving\n",
    "f.write(f\"First rows of plec_result_xgb:\\n{plec_result_xgb.head()}\\n\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_filename = \"Provide_the_pathway_to_your_XGB_run#.csv\"\n",
    "plec_result_xgb.to_csv(csv_filename, index=False)\n",
    "f.write(f\"CSV file saved as {csv_filename}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2386ddef-8105-4f7f-846e-5344fa3d509f",
   "metadata": {},
   "source": [
    "## ANN ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e47aba-0e7f-47c8-a9f0-3e0a7f4e8087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ANN model\n",
    "ann_plec = MLPClassifier(max_iter=9000)\n",
    "\n",
    "# Define the cross-validation strategy (5 stratified folds)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation with AUC\n",
    "cv_scores = cross_val_score(ann_plec, train_features, Train_Class, cv=skf, scoring=make_scorer(roc_auc_score))\n",
    "\n",
    "# Save the results in a DataFrame and export to CSV\n",
    "df_results = pd.DataFrame({'Fold': range(1, 6), 'AUC': cv_scores})\n",
    "df_results.loc[len(df_results)] = ['Mean', np.mean(cv_scores)]\n",
    "df_results.loc[len(df_results)] = ['Std', np.std(cv_scores)]\n",
    "df_results.to_csv('Provide_the_pathway_to_your_ANN_cross_val_results.csv', index=False)\n",
    "\n",
    "# Display the results\n",
    "print(f'AUC per fold: {cv_scores}')\n",
    "print(f'Average AUC: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}')\n",
    "\n",
    "# Train the model on the entire training set\n",
    "ann_plec.fit(train_features, Train_Class)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "prediction_test_ann_plec_class = ann_plec.predict(test_features)\n",
    "prediction_test_ann_plec_prob = ann_plec.predict_proba(test_features)\n",
    "\n",
    "# Display test set results\n",
    "print(\"Class predictions on the test set:\", prediction_test_ann_plec_class)\n",
    "print(\"Prediction probabilities on the test set:\", prediction_test_ann_plec_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7381d923-9b39-4be2-8dd5-41575dbe24e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the output .txt file\n",
    "log_filename = \"Provide_the_pathway_to_your_output_ann_log.txt\"\n",
    "\n",
    "# Ensure the OTS directory exists\n",
    "os.makedirs(\"Provide_the_pathway_to_your_file_results\", exist_ok=True)\n",
    "\n",
    "# Open the file to write the output\n",
    "with open(log_filename, \"w\") as f:\n",
    "    # Verify sizes\n",
    "    f.write(f\"Size of Test_Class: {len(Test_Class)}\\n\")\n",
    "    f.write(f\"Size of prediction_test_ann_plec_class: {len(prediction_test_ann_plec_class)}\\n\")\n",
    "    \n",
    "    # Check content of Test_Class\n",
    "    f.write(f\"Full content of Test_Class:\\n{Test_Class}\\n\")\n",
    "\n",
    "    # Create DataFrame from virtual screening results \n",
    "    plec_result_ann = pd.DataFrame({\n",
    "        \"Active_Prob\": prediction_test_ann_plec_prob[:, 0],\n",
    "        \"Inactive_Prob\": prediction_test_ann_plec_prob[:, 1],\n",
    "        \"Predicted_Class\": prediction_test_ann_plec_class,\n",
    "        \"Real_Class\": Test_Class\n",
    "    })\n",
    "\n",
    "    # Verify DataFrame before saving\n",
    "    f.write(f\"First rows of plec_result_ann:\\n{plec_result_ann.head()}\\n\")\n",
    "\n",
    "    # Save to CSV\n",
    "    csv_filename = \"Provide_the_pathway_to_your_file_where_you_save_result_ANN-run#.csv\"\n",
    "    plec_result_ann.to_csv(csv_filename, index=False)\n",
    "    f.write(f\"CSV file saved as {csv_filename}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb30f83-b84a-4f03-9e4e-af51b35c490e",
   "metadata": {},
   "source": [
    "## DNN ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0f337c-ec8c-412f-8b0b-b7cba3fdf3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the DNN model on the training molecules:\n",
    "Activity_Dict = {\"Active\": 1, \"Inactive\": 0}\n",
    "y_train = [Activity_Dict[item] for item in Train_Class]\n",
    "y_test = [Activity_Dict[item] for item in Test_Class]\n",
    "y_train = np.asarray(y_train).astype(\"float32\")\n",
    "y_test = np.asarray(y_test).astype(\"float32\")\n",
    "\n",
    "dnn_plec = keras.Sequential([\n",
    "    layers.Dense(8192, kernel_regularizer = regularizers.l2(0.001), activation = \"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0),\n",
    "    layers.Dense(4069, activation = \"relu\", kernel_regularizer = regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(2048, activation = \"relu\"),\n",
    "    layers.Dropout(0),\n",
    "    layers.Dense(1, activation = \"sigmoid\")\n",
    "])\n",
    "dnn_plec.compile(optimizer = \"rmsprop\", loss = \"binary_crossentropy\", metrics = ['accuracy'])\n",
    "dnn_plec.fit(np.array(train_features), y_train, epochs = 100, batch_size = 500, verbose = False)\n",
    "\n",
    "#Test the DNN model on the test molecules:\n",
    "prediction_test_dnn_plec_prob = dnn_plec.predict(np.array(test_features))\n",
    "prediction_test_dnn_plec_class = [\"Active\" if num >= 0.5 else \"Inactive\" for num in prediction_test_dnn_plec_prob]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ad0afd-d182-4191-b4f9-332422effb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the output .txt file\n",
    "log_filename = \"Provide_the_pathway_to_your_output_log_DNN_test.txt\"\n",
    "\n",
    "# Open the file to write the output\n",
    "with open(log_filename, \"w\") as f:\n",
    "    # Verify sizes\n",
    "    f.write(f\"Size of Test_Class: {len(Test_Class)}\\n\")\n",
    "    f.write(f\"Size of prediction_test_dnn_plec_class: {len(prediction_test_dnn_plec_class)}\\n\")\n",
    "    \n",
    "    # Check content of Test_Class\n",
    "    f.write(f\"Full content of Test_Class:\\n{Test_Class}\\n\")\n",
    "\n",
    "    # Create DataFrame from virtual screening results\n",
    "    plec_result_dnn_test = pd.DataFrame({\n",
    "        \"Active_Prob\": prediction_test_dnn_plec_prob[:, 0],\n",
    "        \"Predicted_Class\": prediction_test_dnn_plec_class,\n",
    "        \"Real_Class\": Test_Class\n",
    "    })\n",
    "\n",
    "    # Verify DataFrame before saving\n",
    "    f.write(f\"First rows of plec_result_dnn_test:\\n{plec_result_dnn_test.head()}\\n\")\n",
    "\n",
    "    # Ensure the OTS directory exists\n",
    "    os.makedirs(\"Provide_the_pathway_to_your_file_where_save_the_results\", exist_ok=True)\n",
    "\n",
    "    # Save to CSV\n",
    "    csv_filename_test = \"Provide_the_pathway_to_your_file_where_save_the_result_DNN-run#.csv\"\n",
    "    plec_result_dnn_test.to_csv(csv_filename_test, index=False)\n",
    "    f.write(f\"CSV file saved as {csv_filename_test}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f27e947-d04c-409d-8735-f35d146c63b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the activity dictionary\n",
    "Activity_Dict = {\"Active\": 1, \"Inactive\": 0}\n",
    "y_train = np.array([Activity_Dict[item] for item in Train_Class]).astype(\"float32\")\n",
    "y_test = np.array([Activity_Dict[item] for item in Test_Class]).astype(\"float32\")\n",
    "\n",
    "# Set up 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# List to store ROC-AUC values for each fold\n",
    "roc_auc_scores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(train_features)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "    # Split data into training and validation sets for this fold\n",
    "    X_train, X_val = train_features[train_index], train_features[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    # Define the DNN model\n",
    "    tf.random.set_seed(0)\n",
    "    dnn_plec = keras.Sequential([\n",
    "        layers.Dense(8192, kernel_regularizer=regularizers.l2(0.001), activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0),\n",
    "        layers.Dense(4069, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(2048, activation=\"relu\"),\n",
    "        layers.Dropout(0),\n",
    "        layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    dnn_plec.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    dnn_plec.fit(X_train, y_train_fold, epochs=100, batch_size=500, verbose=False)\n",
    "    \n",
    "    # Predict probabilities for the positive class (active)\n",
    "    y_val_pred_prob = dnn_plec.predict(X_val)\n",
    "    \n",
    "    # Compute ROC-AUC for this fold\n",
    "    roc_auc = roc_auc_score(y_val_fold, y_val_pred_prob)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    print(f\"ROC-AUC for Fold {fold + 1}: {roc_auc}\")\n",
    "\n",
    "# Save the ROC-AUC results to a CSV file\n",
    "roc_auc_results = pd.DataFrame({\"Fold\": range(1, 6), \"ROC_AUC\": roc_auc_scores})\n",
    "roc_auc_results.to_csv(\"Provide_the_pathway_to_your_file_where_save_the_ROC_AUC_results\", index=False)\n",
    "\n",
    "# Train the model with all training data to use it on the test set\n",
    "dnn_plec.fit(train_features, y_train, epochs=100, batch_size=500, verbose=False)\n",
    "\n",
    "# Test the model on test molecules\n",
    "prediction_test_dnn_plec_prob = dnn_plec.predict(test_features)\n",
    "prediction_test_dnn_plec_class = ['Active' if num >= 0.5 else \"Inactive\" for num in prediction_test_dnn_plec_prob]\n",
    "\n",
    "# Save the virtual screening results to a CSV file\n",
    "plec_result_dnn = pd.DataFrame({\n",
    "    \"Active_Prob\": prediction_test_dnn_plec_prob[:, 0],\n",
    "    \"Predicted_Class\": prediction_test_dnn_plec_class,\n",
    "    \"Real_Class\": Test_Class\n",
    "})\n",
    "plec_result_dnn.to_csv(\"Provide_the_pathway_to_your_file_where_save_the_result_run\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d22149b-87a1-455f-b7d6-c1b47e5a5956",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Training and Testing of ML Models With Optimization for PLEC ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fcfc44-9416-49ac-bbf7-81c4d1863a52",
   "metadata": {},
   "source": [
    "## SVM ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1540fa90-9254-4382-b1e6-ff6bc2f52224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space for optimal parameters:\n",
    "space = {\"C\": hp.uniform(\"C\", 0, 20),\n",
    "         \"gamma\": hp.choice(\"gamma\", ['scale', 'auto']),\n",
    "         \"kernel\": hp.choice(\"kernel\", ['rbf', 'poly', 'sigmoid'])}\n",
    "\n",
    "# Define the function for hyperparameter tuning:\n",
    "def hyperparameter_tuning_SVM(space):\n",
    "    with parallel_backend(backend=\"multiprocessing\", n_jobs=40):\n",
    "        model = SVC(C=space['C'],\n",
    "                    gamma=space['gamma'],\n",
    "                    kernel=space['kernel'])\n",
    "        model.fit(np.array(train_features), Train_Class)\n",
    "        predicted_train = model.predict(np.array(train_features))\n",
    "        mcc = matthews_corrcoef(Train_Class, predicted_train)\n",
    "    return {'loss': 1-mcc, 'status': STATUS_OK, 'model': model}\n",
    "        \n",
    "# Search for optimal parameters:\n",
    "trials = Trials()\n",
    "best_svm_classification = fmin(fn=hyperparameter_tuning_SVM, space=space, algo=tpe.suggest,\n",
    "                               max_evals=10, trials=trials)\n",
    "best_params = space_eval(space, best_svm_classification)\n",
    "\n",
    "# Optimal parameters:\n",
    "best_params\n",
    "\n",
    "# Train the SVM model on the training molecules using optimal parameters:\n",
    "svm_plec = SVC(C=best_params['C'], gamma=best_params['gamma'], kernel=best_params['kernel'], \n",
    "               probability=True, random_state=0)\n",
    "svm_plec.fit(train_features, Train_Class)\n",
    "\n",
    "# Test the SVM model on the test molecules:\n",
    "prediction_test_svm_plec_class = svm_plec.predict(test_features)\n",
    "prediction_test_svm_plec_prob = svm_plec.predict_proba(test_features)\n",
    "\n",
    "# Define the name of the .txt file for output logging\n",
    "log_filename = \"output_log_SVM.txt\"\n",
    "\n",
    "# Open the file to write the output\n",
    "with open(log_filename, \"w\") as f:\n",
    "    # Check sizes\n",
    "    f.write(f\"Size of Test_Class: {len(Test_Class)}\\n\")\n",
    "    f.write(f\"Size of prediction_test_svm_plec_class: {len(prediction_test_svm_plec_class)}\\n\")\n",
    "    \n",
    "    # Check contents of Test_Class\n",
    "    f.write(f\"Full content of Test_Class:\\n{Test_Class}\\n\")\n",
    "\n",
    "    # Create DataFrame for virtual screening results of the optimized SVM model\n",
    "    plec_result_svm = pd.DataFrame({\n",
    "        \"Active_Prob\": prediction_test_svm_plec_prob[:, 0],\n",
    "        \"Inactive_Prob\": prediction_test_svm_plec_prob[:, 1],\n",
    "        \"Predicted_Class\": prediction_test_svm_plec_class,\n",
    "        \"Real_Class\": Test_Class\n",
    "    })\n",
    "\n",
    "    # Verify DataFrame before saving\n",
    "    f.write(f\"First rows of plec_result_svm:\\n{plec_result_svm.head()}\\n\")\n",
    "\n",
    "    # Save to CSV\n",
    "    csv_filename = \"Provide_the_pathway_to_your_file_where_save_the_result_run.csv\"\n",
    "    plec_result_svm.to_csv(csv_filename, index=False)\n",
    "    f.write(f\"CSV file saved as {csv_filename}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42963f4e-83ce-41b3-aeca-2840d2d731f0",
   "metadata": {},
   "source": [
    "## RF ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cffeff4-1e50-4b78-ba61-32812cdca3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the search space for optimal parameters:\n",
    "space = {\"n_estimators\": hp.uniform(\"n_estimators\", 100, 10000),\n",
    "         \"max_depth\": hp.choice(\"max_depth\", [1, 2, 3, 4, 5, None]),\n",
    "         \"criterion\": hp.choice(\"criterion\", ['gini', 'entropy'])}\n",
    "\n",
    "#Define the function for hyperparameter tuning:\n",
    "def hyperparameter_tuning_randomforest(space):\n",
    "    model = RandomForestClassifier(n_estimators = int(space['n_estimators']),\n",
    "                                   max_depth = space['max_depth'],\n",
    "                                   criterion = space['criterion'], n_jobs = 40)\n",
    "    model.fit(np.array(train_features), Train_Class)\n",
    "    predicted_train = model.predict(np.array(train_features))\n",
    "    mcc = matthews_corrcoef(Train_Class, predicted_train)\n",
    "    return {'loss': 1-mcc, 'status': STATUS_OK, 'model': model}\n",
    "    \n",
    "#Search for optimal parameters:\n",
    "trials = Trials()\n",
    "best_rf_classification = fmin(fn = hyperparameter_tuning_randomforest, space = space, algo = tpe.suggest,\n",
    "                              max_evals = 10, trials = trials)\n",
    "best_params = space_eval(space, best_rf_classification)\n",
    "\n",
    "#Optimal parameters:\n",
    "best_params\n",
    "#Train the RF model on the training molecules, using optimal parameters:\n",
    "rf_plec = RandomForestClassifier(n_estimators = int(best_params['n_estimators']), \n",
    "                                 max_depth = best_params['max_depth'], \n",
    "                                 criterion = best_params['criterion'],\n",
    "                                 max_features = 'sqrt', n_jobs = 30)\n",
    "rf_plec.fit(train_features, Train_Class)\n",
    "\n",
    "#Test the RF model on the test molecules:\n",
    "prediction_test_rf_plec_class = rf_plec.predict(test_features)\n",
    "prediction_test_rf_plec_prob = rf_plec.predict_proba(test_features)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_rf = pd.DataFrame({\"Active_Prob\": prediction_test_rf_plec_prob[:, 0],\n",
    "                               \"Inactive_Prob\": prediction_test_rf_plec_prob[:, 1],\n",
    "                               \"Predicted_Class\": prediction_test_rf_plec_class,\n",
    "                               \"Real_Class\": Test_Class})\n",
    "plec_result_rf.to_csv(\"Provide_the_pathway_to_your_file_where_save_the_result_run.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a56e18-4265-47a8-a203-54ce96260bbe",
   "metadata": {},
   "source": [
    "## XGB ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4104cc5-aec7-4f9a-afda-4bf7bf8fd239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the search space for optimal parameters:\n",
    "space = {\"max_depth\": hp.uniform(\"max_depth\", 3, 18),\n",
    "         \"gamma\": hp.uniform(\"gamma\", 1, 9),\n",
    "         \"reg_alpha\": hp.uniform(\"reg_alpha\", 40, 180),\n",
    "         \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 1), \n",
    "         \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.5, 1),\n",
    "         \"min_child_weight\": hp.uniform(\"min_child_weight\", 0, 10),\n",
    "         \"n_estimators\": hp.uniform(\"n_estimators\", 1000, 5000)} \n",
    "\n",
    "#Define the function for hyperparameter tuning:\n",
    "def hyperparameter_tuning_XGB(space):\n",
    "    model = XGBClassifier(objective = \"binary:logistic\", \n",
    "                          max_depth = int(space['max_depth']),\n",
    "                          gamma = int(space[\"gamma\"]),\n",
    "                          reg_alpha = int(space[\"reg_alpha\"]),\n",
    "                          reg_lambda = space['reg_lambda'],\n",
    "                          colsample_bytree = space[\"colsample_bytree\"],\n",
    "                          min_child_weight = int(space[\"min_child_weight\"]),\n",
    "                          n_estimators = int(space['n_estimators']))\n",
    "    model.fit(np.array(train_features), Train_Class)\n",
    "    predicted_train = model.predict(np.array(train_features))\n",
    "    mcc = matthews_corrcoef(Train_Class, predicted_train)\n",
    "    return {'loss': 1-mcc, 'status': STATUS_OK, 'model': model}\n",
    "    \n",
    "#Search for optimal parameters:\n",
    "trials = Trials()\n",
    "best_xgb_classification = fmin(fn = hyperparameter_tuning_XGB, space = space, algo = tpe.suggest, \n",
    "                               max_evals = 10, trials = trials)\n",
    "best_params = space_eval(space, best_xgb_classification)\n",
    "\n",
    "#Optimal parameters:\n",
    "best_params\n",
    "#Train the XGB model on the training molecules, using optimal parameters:\n",
    "xgb_plec = XGBClassifier(objective = \"binary:logistic\",\n",
    "                         max_depth = int(best_params['max_depth']),\n",
    "                         gamma = int(best_params['gamma']),\n",
    "                         reg_alpha = int(best_params['reg_alpha']),\n",
    "                         reg_lambda = best_params['reg_lambda'],\n",
    "                         colsample_bytree = best_params['colsample_bytree'],\n",
    "                         min_child_weight = int(best_params['min_child_weight']),\n",
    "                         n_estimators = int(best_params['n_estimators']),\n",
    "                         n_jobs = 40, random_state = 0)\n",
    "xgb_plec.fit(np.array(train_features), Train_Class)\n",
    "\n",
    "#Test the XGB model on the test molecules:\n",
    "prediction_test_xgb_plec_class = xgb_plec.predict(np.array(test_features))\n",
    "prediction_test_xgb_plec_prob = xgb_plec.predict_proba(np.array(test_features))\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_xgb = pd.DataFrame({\"Active_Prob\": prediction_test_xgb_plec_prob[:, 0],\n",
    "                                \"Inactive_Prob\": prediction_test_xgb_plec_prob[:, 1],\n",
    "                                \"Predicted_Class\": prediction_test_xgb_plec_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "plec_result_xgb.to_csv(\"Provide_the_pathway_to_your_file_where_save_the_result_run.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56904518-7d40-4572-a41f-dddbdfa5e98c",
   "metadata": {},
   "source": [
    "## ANN ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5e93f6-766d-413e-aa7c-5fc498324e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the search space for optimal parameters:\n",
    "space = {\"hidden_layer_sizes\": hp.uniform(\"hidden_layer_sizes\", 8, 140),\n",
    "         \"activation\": hp.choice(\"activation\", ['relu', 'tanh']),\n",
    "         \"max_iter\": hp.uniform(\"max_iter\", 1000, 10000)}\n",
    "\n",
    "#Define the function for hyperparameter tuning:\n",
    "def hyperparameter_tuning_ANN(space):\n",
    "    model = MLPClassifier(hidden_layer_sizes = int(space['hidden_layer_sizes']),\n",
    "                          activation = space['activation'],\n",
    "                          max_iter = int(space['max_iter']))\n",
    "    model.fit(np.array(train_features), Train_Class)\n",
    "    predicted_train = model.predict(np.array(train_features))\n",
    "    mcc = matthews_corrcoef(Train_Class, predicted_train)\n",
    "    return {'loss': 1-mcc, 'status': STATUS_OK, 'model': model}\n",
    "    \n",
    "#Search for optimal parameters:\n",
    "trials = Trials()\n",
    "best_ann_classification = fmin(fn = hyperparameter_tuning_ANN, space = space, algo = tpe.suggest,\n",
    "                               max_evals = 10, trials = trials)\n",
    "best_params = space_eval(space, best_ann_classification)\n",
    "\n",
    "#Optimal parameters:\n",
    "best_params\n",
    "#Train the ANN model on the training molecules, using optimal parameters:\n",
    "ann_plec = MLPClassifier(hidden_layer_sizes = int(best_params['hidden_layer_sizes']), \n",
    "                         activation = best_params['activation'], \n",
    "                         max_iter = int(best_params['max_iter']), \n",
    "                         random_state = 0)\n",
    "ann_plec.fit(train_features, Train_Class)\n",
    "\n",
    "#Test the ANN model on the test molecules:\n",
    "prediction_test_ann_plec_class = ann_plec.predict(test_features)\n",
    "prediction_test_ann_plec_prob = ann_plec.predict_proba(test_features)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_ann = pd.DataFrame({\"Active_Prob\": prediction_test_ann_plec_prob[:, 0],\n",
    "                                \"Inactive_Prob\": prediction_test_ann_plec_prob[:, 1],\n",
    "                                \"Predicted_Class\": prediction_test_ann_plec_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "plec_result_ann.to_csv(\"Provide_the_pathway_to_your_file_where_save_the_result_run.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f363fc-79b8-4d9a-8c80-2b1601a967d6",
   "metadata": {},
   "source": [
    "## DNN ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f08929f-accf-4d3d-9b11-6a225cda4a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the search space for optimal parameters:\n",
    "space = {'choice': hp.choice('num_layers',\n",
    "                            [ {'layers': 'two'},\n",
    "                              {'layers': 'three',\n",
    "                               'units4': hp.uniform('units4', 64, 8192), \n",
    "                               'dropout3': hp.uniform('dropout3', 0, 1)}\n",
    "                            ]),\n",
    "        'units1': hp.uniform('units1', 64, 8192),\n",
    "        'units2': hp.uniform('units2', 64, 8192),\n",
    "        'units3': hp.uniform('units3', 64, 8192),\n",
    "        'dropout1': hp.uniform('dropout1', 0, 1),\n",
    "        'dropout2': hp.uniform('dropout2', 0, 1),\n",
    "        'batch_size': hp.uniform('batch_size', 128, 500),\n",
    "        'nb_epochs': 100,\n",
    "        'optimizer': hp.choice('optimizer', ['Adadelta','Adam','rmsprop']),\n",
    "        'activation': 'relu'\n",
    "        }\n",
    "Activity_Dict = {\"Active\": 1, \"Inactive\": 0}\n",
    "y_train = [Activity_Dict[item] for item in Train_Class]\n",
    "y_test = [Activity_Dict[item] for item in Test_Class]\n",
    "y_train = np.asarray(y_train).astype(\"float32\")\n",
    "y_test = np.asarray(y_test).astype(\"float32\")\n",
    "\n",
    "#Define the function for hyperparameter tuning:\n",
    "def hyperparameter_tuning_DNN(space):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(abs(int(space['units1'])), kernel_regularizer = regularizers.l2(0.001), activation = \"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(space['dropout1']),\n",
    "        layers.Dense(abs(int(space['units2'])), kernel_regularizer = regularizers.l2(0.001), activation = \"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(abs(int(space['units3'])), kernel_regularizer = regularizers.l2(0.001), activation = \"relu\"),\n",
    "        layers.Dropout(space['dropout2']),\n",
    "        layers.Dense(1, activation = \"sigmoid\")\n",
    "    ])\n",
    "    model.compile(optimizer = 'adam', loss = \"binary_crossentropy\", metrics = ['accuracy'])\n",
    "    model.fit(np.array(train_features), y_train, epochs = 100, batch_size = int(space['batch_size']), verbose = False)\n",
    "    predict_proba = model.predict(np.array(train_features))[:, 0]\n",
    "    predicted_train = ['Active' if num >= 0.5 else \"Inactive\" for num in predict_proba]\n",
    "    #Calculate Mattehews Correlation Coefficient\n",
    "    mcc = matthews_corrcoef(Train_Class, predicted_train)\n",
    "    \n",
    "    return {'loss': 1-mcc, 'status': STATUS_OK, 'model': model, 'MCC': mcc}\n",
    "\n",
    "#Search for optimal parameters:\n",
    "trials = Trials()\n",
    "best_dnn_classification = fmin(hyperparameter_tuning_DNN, space, algo = tpe.suggest, \n",
    "                               max_evals = 10, trials = trials)\n",
    "best_params = space_eval(space, best_dnn_classification)\n",
    "\n",
    "#Optimal parameters:\n",
    "best_params\n",
    "\n",
    "#Train the DNN model on the training molecules, using optimal parameters:\n",
    "tf.random.set_seed(0)\n",
    "dnn_plec = keras.Sequential([\n",
    "    layers.Dense(units = int(best_params['units1']), kernel_regularizer = regularizers.l2(0.001), activation = \"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(best_params['dropout1']),\n",
    "    layers.Dense(units = int(best_params['units2']), kernel_regularizer = regularizers.l2(0.001), activation = \"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(units = int(best_params['units3']), kernel_regularizer = regularizers.l2(0.001), activation = \"relu\"),\n",
    "    layers.Dropout(best_params['dropout2']),\n",
    "    layers.Dense(1, activation = \"sigmoid\")    \n",
    "])\n",
    "dnn_plec.compile(optimizer = best_params['optimizer'], loss = \"binary_crossentropy\", metrics = ['accuracy'])\n",
    "dnn_plec.fit(np.array(train_features), y_train, epochs = 100, \n",
    "             batch_size = int(best_params['batch_size']), verbose = False)\n",
    "\n",
    "#Test the DNN model on the test molecules:\n",
    "prediction_test_dnn_plec_prob = dnn_plec.predict(np.array(test_features))\n",
    "prediction_test_dnn_plec_class = ['Active' if num >= 0.5 else \"Inactive\" for num in prediction_test_dnn_plec_prob]\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_dnn = pd.DataFrame({\"Active_Prob\": prediction_test_dnn_plec_prob[:, 0],\n",
    "                                \"Predicted_Class\": prediction_test_dnn_plec_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "plec_result_dnn.to_csv(\"Provide_the_pathway_to_your_file_where_save_the_result_run.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf28fe3-1c2e-474b-adca-a89efcb861ca",
   "metadata": {},
   "source": [
    "## Run the function to compute Grid ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3043c25-1d75-4859-b8d3-fcffff804106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the pathway to the training molecules (SDF or multi-SDF)\n",
    "train_sdf = opd.read_sdf(\"Provide_the_pathway_to_your_training_molecules.sdf\")\n",
    "train = train_sdf.merge(train_data.drop_duplicates(subset=['mol_name']), how='left', on='mol_name')\n",
    "\n",
    "# Split the multi-SDF training data into individual SDF structures\n",
    "for i in range(train_sdf.shape[0]):\n",
    "    each_sdf = train_sdf.iloc[[i]]\n",
    "    each_name = list(each_sdf['mol_name'])[0]\n",
    "    out_path = \"Provide_the_directory_where_you_want_to_save_individual_training_SDFs/\" + str(each_name) + \".sdf\"\n",
    "    ChemDataFrame.to_sdf(each_sdf, out_path)\n",
    "training_set = glob.glob(\"Provide_the_directory_where_you_saved_individual_training_SDFs/*\")\n",
    "\n",
    "# Provide the pathway to the test molecules (SDF or multi-SDF)\n",
    "test_sdf = opd.read_sdf(\"Provide_the_pathway_to_your_test_molecules.sdf\")\n",
    "test = test_sdf.merge(test_data.drop_duplicates(subset=['mol_name']), how='left', on='mol_name')\n",
    "\n",
    "# Split the multi-SDF test data into individual SDF structures\n",
    "for i in range(test_sdf.shape[0]):\n",
    "    each_sdf = test_sdf.iloc[[i]]\n",
    "    each_name = list(each_sdf['mol_name'])[0]\n",
    "    out_path = \"Provide_the_directory_where_you_want_to_save_individual_test_SDFs/\" + str(each_name) + \".sdf\"\n",
    "    ChemDataFrame.to_sdf(each_sdf, out_path)\n",
    "test_set = glob.glob(\"Provide_the_directory_where_you_saved_individual_test_SDFs/*\")\n",
    "\n",
    "# Extract the structures of all training and test molecules\n",
    "train_mols = train['mol']\n",
    "test_mols = test['mol']\n",
    "\n",
    "# Provide the pathway(s) to the training and test target/receptor structure(s)\n",
    "protein_train = \"Provide_the_pathway_to_your_training_protein_structure.pdb\"\n",
    "protein_test = \"Provide_the_pathway_to_your_test_protein_structure.pdb\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c377a3-a1e0-4bc0-9970-784ffc467ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Users may keep only one of the following two functions if the training target/receptor structure is the same as the test target/receptor structure\n",
    "#Users may change the parameters (voxel_width, feature_types, ecfp_power, splif_power) if they wish\n",
    "featurizer = RdkitGridFeaturizer(voxel_width = 16.0, feature_types = [\"ecfp\", \"splif\", \"hbond\", \"salt_bridge\"], ecfp_power = 9, splif_power = 9, flatten = True, verbose = False)\n",
    "def extract_grid_feature_train(ligand_file):\n",
    "    try:\n",
    "        feature = featurizer._featurize((ligand_file, protein_train))\n",
    "        return feature\n",
    "    except:\n",
    "        pass\n",
    "def extract_grid_feature_test(ligand_file):\n",
    "    try:\n",
    "        feature = featurizer._featurize((ligand_file, protein_test))\n",
    "        return feature\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "#Users may choose another number of cores (num_cores) that corresponds to their computing resources\n",
    "num_cores = 20\n",
    "train_features = Parallel(n_jobs = num_cores, backend = \"multiprocessing\")(delayed(extract_grid_feature_train)(ligand_file) for ligand_file in tqdm(training_set))\n",
    "test_features = Parallel(n_jobs = num_cores, backend = \"multiprocessing\")(delayed(extract_grid_feature_test)(ligand_file) for ligand_file in tqdm(test_set))\n",
    "\n",
    "#Export grid features as npy files:\n",
    "np.save('features_grid_train.npy', train_features)\n",
    "\n",
    "test_features = np.array(test_features, dtype=np.float32)  # Asegurar una estructura homogénea\n",
    "np.save('features_grid_test.npy', test_features)\n",
    "\n",
    "\n",
    "#Load grid features for the next stages:\n",
    "train_grid_features = np.load(\"features_grid_train.npy\", allow_pickle=True)\n",
    "#test_grid_features = np.load(\"features_grid_test.npy\", allow_pickle=True)\n",
    "test_grid_features = np.load(\"features_grid_test.npy\", allow_pickle=False)  # Evita dtype=object\n",
    "test_grid_features = np.vstack(test_grid_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de90c2a5-e615-4765-9500-e3549c0dad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the number of molecules at each step\n",
    "training_count = len(training_set)\n",
    "grid_features_count = len(train_grid_features)\n",
    "train_class_count = len(Train_Class)\n",
    "\n",
    "# Save sizes in CSV\n",
    "debug_sizes = pd.DataFrame({\n",
    "    \"Variable\": [\"training_set\", \"train_grid_features\", \"Train_Class\"],\n",
    "    \"Length\": [training_count, grid_features_count, train_class_count]\n",
    "})\n",
    "debug_sizes.to_csv(\"debug_sizes.csv\", index=False)\n",
    "\n",
    "# Check for duplicate files in training_set\n",
    "file_counts = pd.Series(training_set).value_counts()\n",
    "duplicates = file_counts[file_counts > 1]\n",
    "\n",
    "# Create dataframe with duplicate information\n",
    "duplicates_df = pd.DataFrame({\n",
    "    \"Filename\": duplicates.index,\n",
    "    \"Occurrences\": duplicates.values\n",
    "})\n",
    "duplicates_df.to_csv(\"duplicates_check.csv\", index=False)\n",
    "\n",
    "# Check for extra files in training_set compared to Train_Class\n",
    "training_filenames = [f.split(\"/\")[-1].replace(\".sdf\", \"\") for f in training_set]\n",
    "train_class_names = list(train['mol_name'])  # Ensure the names match\n",
    "\n",
    "extra_files = set(training_filenames) - set(train_class_names)\n",
    "\n",
    "# Save extra files in CSV\n",
    "extra_files_df = pd.DataFrame({\"Extra_Files\": list(extra_files)})\n",
    "extra_files_df.to_csv(\"extra_files.csv\", index=False)\n",
    "\n",
    "# Trim train_grid_features if it has more elements\n",
    "if grid_features_count > train_class_count:\n",
    "    train_grid_features = train_grid_features[:train_class_count]\n",
    "    print(\"✅ Adjusted: train_grid_features now matches Train_Class\")\n",
    "\n",
    "# Ensure train_grid_features is a properly formatted matrix for sklearn\n",
    "train_grid_features_fixed = np.array([np.array(f).flatten() if isinstance(f, (list, np.ndarray)) else np.full((1,), f) for f in train_grid_features])\n",
    "\n",
    "# Save the corrected array to files\n",
    "np.save(\"train_grid_features_fixed.npy\", train_grid_features_fixed)\n",
    "train_grid_features_df = pd.DataFrame(train_grid_features_fixed)\n",
    "train_grid_features_df.to_csv(\"train_grid_features_fixed.csv\", index=False)\n",
    "\n",
    "# Load grid features for the next stages\n",
    "train_grid_features = np.load(\"train_grid_features_fixed.npy\", allow_pickle=True)\n",
    "test_grid_features = np.load(\"features_grid_test.npy\", allow_pickle=True)\n",
    "\n",
    "print(\"✅ The following files have been generated:\")\n",
    "print(\"- debug_sizes.csv → Size information\")\n",
    "print(\"- duplicates_check.csv → Duplicate file information\")\n",
    "print(\"- extra_files.csv → List of extra files in training_set\")\n",
    "print(\"- train_grid_features_fixed.npy → Corrected train_grid_features in numpy format\")\n",
    "print(\"- train_grid_features_fixed.csv → Corrected train_grid_features in CSV format\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3fc4b6-979c-4474-aa04-8c08936ea116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Verify the number of molecules at each step\n",
    "training_count = len(training_set)\n",
    "grid_features_count = len(train_grid_features)\n",
    "train_class_count = len(Train_Class)\n",
    "\n",
    "# Save sizes in CSV\n",
    "debug_sizes = pd.DataFrame({\n",
    "    \"Variable\": [\"training_set\", \"train_grid_features\", \"Train_Class\"],\n",
    "    \"Length\": [training_count, grid_features_count, train_class_count]\n",
    "})\n",
    "debug_sizes.to_csv(\"debug_sizes.csv\", index=False)\n",
    "\n",
    "# Check for duplicate files in training_set\n",
    "file_counts = pd.Series(training_set).value_counts()\n",
    "duplicates = file_counts[file_counts > 1]\n",
    "\n",
    "# Create dataframe with duplicate information\n",
    "duplicates_df = pd.DataFrame({\n",
    "    \"Filename\": duplicates.index,\n",
    "    \"Occurrences\": duplicates.values\n",
    "})\n",
    "duplicates_df.to_csv(\"duplicates_check.csv\", index=False)\n",
    "\n",
    "# Check for extra files in training_set compared to Train_Class\n",
    "training_filenames = [f.split(\"/\")[-1].replace(\".sdf\", \"\") for f in training_set]\n",
    "train_class_names = list(train['mol_name'])  # Ensure the names match\n",
    "\n",
    "extra_files = set(training_filenames) - set(train_class_names)\n",
    "\n",
    "# Save extra files in CSV\n",
    "extra_files_df = pd.DataFrame({\"Extra_Files\": list(extra_files)})\n",
    "extra_files_df.to_csv(\"extra_files.csv\", index=False)\n",
    "\n",
    "# Trim train_grid_features if it has more elements\n",
    "if grid_features_count > train_class_count:\n",
    "    train_grid_features = train_grid_features[:train_class_count]\n",
    "    print(\"✅ Adjusted: train_grid_features now matches Train_Class\")\n",
    "\n",
    "# Ensure train_grid_features is a properly formatted matrix for sklearn\n",
    "train_grid_features_fixed = np.array([np.array(f).flatten() if isinstance(f, (list, np.ndarray)) else np.full((1,), f) for f in train_grid_features])\n",
    "\n",
    "# Save the corrected array to files\n",
    "np.save(\"train_grid_features_fixed.npy\", train_grid_features_fixed)\n",
    "train_grid_features_df = pd.DataFrame(train_grid_features_fixed)\n",
    "train_grid_features_df.to_csv(\"train_grid_features_fixed.csv\", index=False)\n",
    "\n",
    "# Load grid features for the next stages\n",
    "train_grid_features = np.load(\"train_grid_features_fixed.npy\", allow_pickle=True)\n",
    "test_grid_features = np.load(\"features_grid_test.npy\", allow_pickle=True)\n",
    "\n",
    "# Debugging test_grid_features\n",
    "debug_info = []\n",
    "\n",
    "debug_info.append([\"Train features shape\", train_grid_features.shape])\n",
    "debug_info.append([\"Test features shape\", test_grid_features.shape])\n",
    "\n",
    "if isinstance(test_grid_features, pd.DataFrame):\n",
    "    dtypes_info = test_grid_features.dtypes.astype(str).to_dict()\n",
    "    debug_info.append([\"Test feature types\", dtypes_info])\n",
    "    if any(test_grid_features.dtypes == 'object'):\n",
    "        test_grid_features = test_grid_features.astype(float)\n",
    "else:\n",
    "    debug_info.append([\"Test feature dtype\", str(test_grid_features.dtype)])\n",
    "\n",
    "nested_list_issues = []\n",
    "for i, row in enumerate(test_grid_features):\n",
    "    if isinstance(row, list) or isinstance(row, np.ndarray):\n",
    "        nested_list_issues.append(f\"Row {i} contains a nested list instead of individual values.\")\n",
    "\n",
    "if nested_list_issues:\n",
    "    debug_info.append([\"Nested list issues\", nested_list_issues])\n",
    "\n",
    "row_lengths = [len(row) if isinstance(row, (list, np.ndarray)) else 1 for row in test_grid_features]\n",
    "max_row_length = max(row_lengths)\n",
    "\n",
    "if any(length != max_row_length for length in row_lengths):\n",
    "    debug_info.append([\"Inconsistent row lengths\", row_lengths])\n",
    "\n",
    "test_grid_features = np.array([np.ravel(row) if isinstance(row, (list, np.ndarray)) else row for row in test_grid_features])\n",
    "\n",
    "df_debug = pd.DataFrame(debug_info, columns=[\"Description\", \"Value\"])\n",
    "df_debug.to_csv(\"debugging_output-test.csv\", index=False)\n",
    "\n",
    "print(\"✅ The following files have been generated:\")\n",
    "print(\"- debug_sizes.csv → Size information\")\n",
    "print(\"- duplicates_check.csv → Duplicate file information\")\n",
    "print(\"- extra_files.csv → List of extra files in training_set\")\n",
    "print(\"- train_grid_features_fixed.npy → Corrected train_grid_features in numpy format\")\n",
    "print(\"- train_grid_features_fixed.csv → Corrected train_grid_features in CSV format\")\n",
    "print(\"- debugging_output-test.csv → Debugging information for test_grid_features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d98a07c-6622-4ffc-959e-a421c041dfe5",
   "metadata": {},
   "source": [
    "## Training and Testing of ML Models Without Optimization but With Cross-Validation ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1b6916-0762-4b50-a2ae-9c89ab9d1075",
   "metadata": {},
   "source": [
    "## SVM ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34dacd5-b476-4cb0-a5b1-7d6c904ded7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SVM model\n",
    "svm_grid = SVC(degree=3, kernel=\"rbf\", probability=True, random_state=0)\n",
    "\n",
    "# Configure 5-fold stratified cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# List to store the AUC-ROC results for each fold\n",
    "auc_scores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train_grid_features, Train_Class)):\n",
    "    X_train, X_val = train_grid_features[train_idx], train_grid_features[val_idx]\n",
    "    y_train, y_val = Train_Class[train_idx], Train_Class[val_idx]\n",
    "    \n",
    "    # Train the model on the training fold\n",
    "    svm_grid.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities on the validation fold\n",
    "    y_val_prob = svm_grid.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Calculate AUC-ROC for this fold\n",
    "    auc = roc_auc_score(y_val, y_val_prob)\n",
    "    auc_scores.append(auc)\n",
    "    \n",
    "    print(f\"Fold {fold + 1}: AUC-ROC = {auc:.4f}\")\n",
    "\n",
    "# Save AUC-ROC results to a CSV file\n",
    "auc_results = pd.DataFrame({\"Fold\": range(1, 6), \"AUC-ROC\": auc_scores})\n",
    "auc_results.to_csv(\"Provide_the_pathway_to_your_file_where_save_the_result_run.csv\", index=False)\n",
    "\n",
    "# Train the final model on the entire training set\n",
    "svm_grid.fit(train_grid_features, Train_Class)\n",
    "\n",
    "# Predict on the test set\n",
    "prediction_test_svm_grid_class = svm_grid.predict(test_grid_features)\n",
    "prediction_test_svm_grid_prob = svm_grid.predict_proba(test_grid_features)\n",
    "\n",
    "# Save prediction results to a CSV file\n",
    "grid_result_svm = pd.DataFrame({\n",
    "    \"Active_Prob\": prediction_test_svm_grid_prob[:, 0],\n",
    "    \"Inactive_Prob\": prediction_test_svm_grid_prob[:, 1],\n",
    "    \"Predicted_Class\": prediction_test_svm_grid_class,\n",
    "    \"Real_Class\": Test_Class\n",
    "})\n",
    "grid_result_svm.to_csv(\"Provide_the_pathway_to_your_file_where_save_the_result_run.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4af0e0-0b4f-4438-b659-c6444a715d56",
   "metadata": {},
   "source": [
    "## RF ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67896bf3-e96f-442c-8d9f-d5fcb7674021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Random Forest model with specified parameters\n",
    "rf_grid = RandomForestClassifier(n_estimators=500, n_jobs=30, random_state=0)\n",
    "\n",
    "# Configure 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# List to store ROC-AUC values for each fold\n",
    "roc_auc_scores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, val_index in kf.split(train_grid_features):\n",
    "    # Split data into training and validation for this fold\n",
    "    X_train, X_val = train_grid_features[train_index], train_grid_features[val_index]\n",
    "    y_train, y_val = Train_Class[train_index], Train_Class[val_index]\n",
    "    \n",
    "    # Train the model\n",
    "    rf_grid.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities for the positive class (active)\n",
    "    y_val_pred_prob = rf_grid.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Calculate ROC-AUC for this fold\n",
    "    roc_auc = roc_auc_score(y_val, y_val_pred_prob)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "\n",
    "# Save ROC-AUC results to a CSV file\n",
    "roc_auc_results = pd.DataFrame({\"Fold\": range(1, 6), \"ROC_AUC\": roc_auc_scores})\n",
    "roc_auc_results.to_csv(\"Provide_the_pathway_to_your_file_where_save_the_result_run.csv\", index=False)\n",
    "\n",
    "# Train the model on the entire training set for testing\n",
    "rf_grid.fit(train_grid_features, Train_Class)\n",
    "\n",
    "# Test the model on the test molecules\n",
    "prediction_test_rf_grid_class = rf_grid.predict(test_grid_features)\n",
    "prediction_test_rf_grid_prob = rf_grid.predict_proba(test_grid_features)\n",
    "\n",
    "# Save virtual screening results to a CSV file\n",
    "grid_result_rf = pd.DataFrame({\n",
    "    \"Active_Prob\": prediction_test_rf_grid_prob[:, 0],\n",
    "    \"Inactive_Prob\": prediction_test_rf_grid_prob[:, 1],\n",
    "    \"Predicted_Class\": prediction_test_rf_grid_class,\n",
    "    \"Real_Class\": Test_Class\n",
    "})\n",
    "grid_result_rf.to_csv(\"Provide_the_pathway_to_your_file_where_save_the_result_run.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fa1a84-46e3-48f0-8e9a-ca3430998a4e",
   "metadata": {},
   "source": [
    "## XGB ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10fd6f3-d5e8-4590-8473-a5c87e07ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the XGBoost model with optimized parameters\n",
    "xgb_grid = XGBClassifier(n_estimators=745, max_depth=7, learning_rate=0.05, n_jobs=40, random_state=0)\n",
    "\n",
    "# Configure 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# List to store ROC-AUC values for each fold\n",
    "roc_auc_scores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, val_index in kf.split(train_grid_features):\n",
    "    # Split data into training and validation for this fold\n",
    "    X_train, X_val = train_grid_features[train_index], train_grid_features[val_index]\n",
    "    y_train, y_val = Train_Class[train_index], Train_Class[val_index]\n",
    "    \n",
    "    # Train the model\n",
    "    xgb_grid.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities for the positive class (active)\n",
    "    y_val_pred_prob = xgb_grid.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Calculate ROC-AUC for this fold\n",
    "    roc_auc = roc_auc_score(y_val, y_val_pred_prob)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "\n",
    "# Save ROC-AUC results to a CSV file\n",
    "roc_auc_results = pd.DataFrame({\"Fold\": range(1, 6), \"ROC_AUC\": roc_auc_scores})\n",
    "roc_auc_results.to_csv(\"Provide_the_pathway_to_your_file_where_save_the_result_run.csv\", index=False)\n",
    "\n",
    "# Train the model on the entire training set for testing\n",
    "xgb_grid.fit(np.array(train_grid_features), Train_Class)\n",
    "\n",
    "# Test the model on the test molecules\n",
    "prediction_test_xgb_grid_class = xgb_grid.predict(np.array(test_grid_features))\n",
    "prediction_test_xgb_grid_prob = xgb_grid.predict_proba(np.array(test_grid_features))\n",
    "\n",
    "# Save virtual screening results to a CSV file\n",
    "grid_result_xgb = pd.DataFrame({\n",
    "    \"Active_Prob\": prediction_test_xgb_grid_prob[:, 0],\n",
    "    \"Inactive_Prob\": prediction_test_xgb_grid_prob[:, 1],\n",
    "    \"Predicted_Class\": prediction_test_xgb_grid_class,\n",
    "    \"Real_Class\": Test_Class\n",
    "})\n",
    "grid_result_xgb.to_csv(\"Provide_the_pathway_to_your_file_where_save_the_result_run.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815ee6ec-9ce8-4c4c-8aae-3ad6512a941d",
   "metadata": {},
   "source": [
    "## ANN ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ec63bb-d698-416a-b7bd-037575adf770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ANN model\n",
    "ann_grid = MLPClassifier(max_iter=500, random_state=0)\n",
    "\n",
    "# Configure 5-fold stratified cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# List to store AUC-ROC results for each fold\n",
    "auc_scores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train_grid_features, Train_Class)):\n",
    "    X_train, X_val = train_grid_features[train_idx], train_grid_features[val_idx]\n",
    "    y_train, y_val = Train_Class[train_idx], Train_Class[val_idx]\n",
    "    \n",
    "    # Train the model on the training fold\n",
    "    ann_grid.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities on the validation fold\n",
    "    y_val_prob = ann_grid.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Compute AUC-ROC for this fold\n",
    "    auc = roc_auc_score(y_val, y_val_prob)\n",
    "    auc_scores.append(auc)\n",
    "    \n",
    "    print(f\"Fold {fold + 1}: AUC-ROC = {auc:.4f}\")\n",
    "\n",
    "# Save AUC-ROC results to a CSV file\n",
    "auc_results = pd.DataFrame({\"Fold\": range(1, 6), \"AUC-ROC\": auc_scores})\n",
    "auc_results.to_csv(\"Provide_the_pathway_to_your_file_where_save_the_result_run_CV.csv\", index=False)\n",
    "\n",
    "# Train the final model on the entire training set\n",
    "ann_grid.fit(train_grid_features, Train_Class)\n",
    "\n",
    "# Predict on the test set\n",
    "prediction_test_ann_grid_class = ann_grid.predict(test_grid_features)\n",
    "prediction_test_ann_grid_prob = ann_grid.predict_proba(test_grid_features)\n",
    "\n",
    "# Save prediction results to a CSV file\n",
    "grid_result_ann = pd.DataFrame({\n",
    "    \"Active_Prob\": prediction_test_ann_grid_prob[:, 0],\n",
    "    \"Inactive_Prob\": prediction_test_ann_grid_prob[:, 1],\n",
    "    \"Predicted_Class\": prediction_test_ann_grid_class,\n",
    "    \"Real_Class\": Test_Class\n",
    "})\n",
    "grid_result_ann.to_csv(\"Provide_the_pathway_to_your_file_where_save_the_result_run.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a144646-4fe9-45ea-96e0-800bc1e6de69",
   "metadata": {},
   "source": [
    "## DNN ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147f1b7b-1e3f-4fd5-82c6-c90631e6e881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the activity dictionary\n",
    "Activity_Dict = {\"Active\": 1, \"Inactive\": 0}\n",
    "y_train = np.array([Activity_Dict[item] for item in Train_Class]).astype(\"float32\")\n",
    "y_test = np.array([Activity_Dict[item] for item in Test_Class]).astype(\"float32\")\n",
    "\n",
    "# Configure 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# List to store ROC-AUC values for each fold\n",
    "roc_auc_scores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(train_grid_features)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "    # Split data into training and validation for this fold\n",
    "    X_train, X_val = train_grid_features[train_index], train_grid_features[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    # Define the DNN model\n",
    "    tf.random.set_seed(0)\n",
    "    dnn_grid = keras.Sequential([\n",
    "        layers.Dense(8192, kernel_regularizer=regularizers.l2(0), activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0),\n",
    "        layers.Dense(4069, activation=\"relu\", kernel_regularizer=regularizers.l2(0)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(2048, activation=\"relu\"),\n",
    "        layers.Dropout(0),\n",
    "        layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    dnn_grid.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    dnn_grid.fit(X_train, y_train_fold, epochs=100, batch_size=500, verbose=False)\n",
    "    \n",
    "    # Predict probabilities for the positive (active) class\n",
    "    y_val_pred_prob = dnn_grid.predict(X_val)\n",
    "    \n",
    "    # Compute ROC-AUC for this fold\n",
    "    roc_auc = roc_auc_score(y_val_fold, y_val_pred_prob)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    print(f\"ROC-AUC for Fold {fold + 1}: {roc_auc}\")\n",
    "\n",
    "# Save ROC-AUC results to a CSV file\n",
    "roc_auc_results = pd.DataFrame({\"Fold\": range(1, 6), \"ROC_AUC\": roc_auc_scores})\n",
    "roc_auc_results.to_csv(\"Provide_the_pathway_to_your_file_where_save_the_result_run_CV.csv\", index=False)\n",
    "\n",
    "# Train the model with all training data for testing\n",
    "dnn_grid.fit(train_grid_features, y_train, epochs=100, batch_size=500, verbose=False)\n",
    "\n",
    "# Test the model on test molecules\n",
    "prediction_test_dnn_grid_prob = dnn_grid.predict(test_grid_features)\n",
    "prediction_test_dnn_grid_class = ['Active' if num >= 0.5 else \"Inactive\" for num in prediction_test_dnn_grid_prob]\n",
    "\n",
    "# Save virtual screening results to a CSV file\n",
    "grid_result_dnn = pd.DataFrame({\n",
    "    \"Active_Prob\": prediction_test_dnn_grid_prob[:, 0],\n",
    "    \"Predicted_Class\": prediction_test_dnn_grid_class,\n",
    "    \"Real_Class\": Test_Class\n",
    "})\n",
    "grid_result_dnn.to_csv(\"Provide_the_pathway_to_your_file_where_save_the_result_run.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08e0a5e-a53c-4da5-a5cf-7e3a68125df7",
   "metadata": {},
   "source": [
    "## Training and Testing of ML Models With Optimization for Grid ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92caa1b6-5e69-4028-933f-9c52c78842c9",
   "metadata": {},
   "source": [
    "## SVM ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367249a3-7ef2-4440-8deb-fa2df239ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space for optimal parameters:\n",
    "space = {\"C\": hp.uniform(\"C\", 0, 20),\n",
    "         \"gamma\": hp.choice(\"gamma\", ['scale', 'auto']),\n",
    "         \"kernel\": hp.choice(\"kernel\", ['rbf', 'poly', 'sigmoid'])}\n",
    "\n",
    "# Define the function for hyperparameter tuning:\n",
    "def hyperparameter_tuning_SVM(space):\n",
    "    with parallel_backend(backend=\"multiprocessing\", n_jobs=40):\n",
    "        model = SVC(C=space['C'],\n",
    "                    gamma=space['gamma'],\n",
    "                    kernel=space['kernel'])\n",
    "        model.fit(np.array(train_grid_features), Train_Class)\n",
    "        predicted_train = model.predict(np.array(train_grid_features))\n",
    "        mcc = matthews_corrcoef(Train_Class, predicted_train)\n",
    "    return {'loss': 1-mcc, 'status': STATUS_OK, 'model': model}\n",
    "        \n",
    "# Search for optimal parameters:\n",
    "trials = Trials()\n",
    "best_svm_classification = fmin(fn=hyperparameter_tuning_SVM, space=space, algo=tpe.suggest,\n",
    "                               max_evals=10, trials=trials)\n",
    "best_params = space_eval(space, best_svm_classification)\n",
    "\n",
    "# Optimal parameters:\n",
    "best_params\n",
    "\n",
    "# Train the SVM model on the training molecules using optimal parameters:\n",
    "svm_grid = SVC(C=best_params['C'], gamma=best_params['gamma'], kernel=best_params['kernel'], \n",
    "               probability=True, random_state=0)\n",
    "svm_grid.fit(train_grid_features, Train_Class)\n",
    "\n",
    "# Test the SVM model on the test molecules:\n",
    "prediction_test_svm_grid_class = svm_grid.predict(test_grid_features)\n",
    "prediction_test_svm_grid_prob = svm_grid.predict_proba(test_grid_features)\n",
    "\n",
    "# Define the name of the .txt file for output logging\n",
    "log_filename = \"output_log_SVM.txt\"\n",
    "\n",
    "# Open the file to write the output\n",
    "with open(log_filename, \"w\") as f:\n",
    "    # Check sizes\n",
    "    f.write(f\"Size of Test_Class: {len(Test_Class)}\\n\")\n",
    "    f.write(f\"Size of prediction_test_svm_grid_class: {len(prediction_test_svm_grid_class)}\\n\")\n",
    "    \n",
    "    # Check contents of Test_Class\n",
    "    f.write(f\"Full content of Test_Class:\\n{Test_Class}\\n\")\n",
    "\n",
    "    # Create DataFrame for virtual screening results of the optimized SVM model\n",
    "    grid_result_svm = pd.DataFrame({\n",
    "        \"Active_Prob\": prediction_test_svm_grid_prob[:, 0],\n",
    "        \"Inactive_Prob\": prediction_test_svm_grid_prob[:, 1],\n",
    "        \"Predicted_Class\": prediction_test_svm_grid_class,\n",
    "        \"Real_Class\": Test_Class\n",
    "    })\n",
    "\n",
    "    # Verify DataFrame before saving\n",
    "    f.write(f\"First rows of grid_result_svm:\\n{grid_result_svm.head()}\\n\")\n",
    "\n",
    "    # Save to CSV\n",
    "    csv_filename = \"Provide_the_pathway_to_your_file_where_save_the_result_run.csv\"\n",
    "    grid_result_svm.to_csv(csv_filename, index=False)\n",
    "    f.write(f\"CSV file saved as {csv_filename}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e6f113-cfb0-42ed-887c-008df6a7bd14",
   "metadata": {},
   "source": [
    "## RF ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb62b6da-0b51-44a6-827d-1c92dd84379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space for optimal parameters:\n",
    "space = {\"n_estimators\": hp.uniform(\"n_estimators\", 100, 10000),\n",
    "         \"max_depth\": hp.choice(\"max_depth\", [1, 2, 3, 4, 5, None]),\n",
    "         \"criterion\": hp.choice(\"criterion\", ['gini', 'entropy'])}\n",
    "\n",
    "# Define the function for hyperparameter tuning:\n",
    "def hyperparameter_tuning_randomforest(space):\n",
    "    model = RandomForestClassifier(n_estimators=int(space['n_estimators']),\n",
    "                                   max_depth=space['max_depth'],\n",
    "                                   criterion=space['criterion'], n_jobs=40)\n",
    "    model.fit(np.array(train_grid_features), Train_Class)\n",
    "    predicted_train = model.predict(np.array(train_grid_features))\n",
    "    mcc = matthews_corrcoef(Train_Class, predicted_train)\n",
    "    return {'loss': 1-mcc, 'status': STATUS_OK, 'model': model}\n",
    "    \n",
    "# Search for optimal parameters:\n",
    "trials = Trials()\n",
    "best_rf_classification = fmin(fn=hyperparameter_tuning_randomforest, space=space, algo=tpe.suggest,\n",
    "                              max_evals=10, trials=trials)\n",
    "best_params = space_eval(space, best_rf_classification)\n",
    "\n",
    "# Optimal parameters:\n",
    "best_params\n",
    "\n",
    "# Train the RF model on the training molecules, using optimal parameters:\n",
    "rf_grid = RandomForestClassifier(n_estimators=int(best_params['n_estimators']), \n",
    "                                 max_depth=best_params['max_depth'], \n",
    "                                 criterion=best_params['criterion'],\n",
    "                                 max_features='sqrt', n_jobs=30)\n",
    "rf_grid.fit(train_grid_features, Train_Class)\n",
    "\n",
    "# Test the RF model on the test molecules:\n",
    "prediction_test_rf_grid_class = rf_grid.predict(test_grid_features)\n",
    "prediction_test_rf_grid_prob = rf_grid.predict_proba(test_grid_features)\n",
    "\n",
    "# Get virtual screening results on the test molecules and export results to a csv file:\n",
    "grid_result_rf = pd.DataFrame({\"Active_Prob\": prediction_test_rf_grid_prob[:, 0],\n",
    "                               \"Inactive_Prob\": prediction_test_rf_grid_prob[:, 1],\n",
    "                               \"Predicted_Class\": prediction_test_rf_grid_class,\n",
    "                               \"Real_Class\": Test_Class})\n",
    "grid_result_rf.to_csv(\"Provide_the_pathway_to_your_file_where_save_the_result_run.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22292d52-5d69-45ab-b532-8eda01711cb9",
   "metadata": {},
   "source": [
    "## XGB ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2c3dd7-429e-4deb-a379-b7fe664215ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space for optimal parameters:\n",
    "space = {\n",
    "    \"max_depth\": hp.uniform(\"max_depth\", 3, 18),\n",
    "    \"gamma\": hp.uniform(\"gamma\", 1, 9),\n",
    "    \"reg_alpha\": hp.uniform(\"reg_alpha\", 40, 180),\n",
    "    \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 1), \n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.5, 1),\n",
    "    \"min_child_weight\": hp.uniform(\"min_child_weight\", 0, 10),\n",
    "    \"n_estimators\": hp.uniform(\"n_estimators\", 1000, 5000)\n",
    "} \n",
    "\n",
    "# Define the function for hyperparameter tuning:\n",
    "def hyperparameter_tuning_XGB(space):\n",
    "    model = XGBClassifier(\n",
    "        objective=\"binary:logistic\", \n",
    "        max_depth=int(space['max_depth']),\n",
    "        gamma=int(space[\"gamma\"]),\n",
    "        reg_alpha=int(space[\"reg_alpha\"]),\n",
    "        reg_lambda=space['reg_lambda'],\n",
    "        colsample_bytree=space[\"colsample_bytree\"],\n",
    "        min_child_weight=int(space[\"min_child_weight\"]),\n",
    "        n_estimators=int(space['n_estimators']),\n",
    "        n_jobs=40,\n",
    "        random_state=0\n",
    "    )\n",
    "    model.fit(np.array(train_grid_features), Train_Class)\n",
    "    predicted_train = model.predict(np.array(train_grid_features))\n",
    "    mcc = matthews_corrcoef(Train_Class, predicted_train)\n",
    "    return {'loss': 1 - mcc, 'status': STATUS_OK, 'model': model}\n",
    "    \n",
    "# Search for optimal parameters:\n",
    "trials = Trials()\n",
    "best_xgb_classification = fmin(\n",
    "    fn=hyperparameter_tuning_XGB, \n",
    "    space=space, \n",
    "    algo=tpe.suggest, \n",
    "    max_evals=10, \n",
    "    trials=trials\n",
    ")\n",
    "best_params = space_eval(space, best_xgb_classification)\n",
    "\n",
    "# Train the XGB model on the training molecules, using optimal parameters:\n",
    "xgb_grid = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    max_depth=int(best_params['max_depth']),\n",
    "    gamma=int(best_params['gamma']),\n",
    "    reg_alpha=int(best_params['reg_alpha']),\n",
    "    reg_lambda=best_params['reg_lambda'],\n",
    "    colsample_bytree=best_params['colsample_bytree'],\n",
    "    min_child_weight=int(best_params['min_child_weight']),\n",
    "    n_estimators=int(best_params['n_estimators']),\n",
    "    n_jobs=40, \n",
    "    random_state=0\n",
    ")\n",
    "xgb_grid.fit(np.array(train_grid_features), Train_Class)\n",
    "\n",
    "# Test the XGB model on the test molecules:\n",
    "prediction_test_xgb_grid_class = xgb_grid.predict(np.array(test_grid_features))\n",
    "prediction_test_xgb_grid_prob = xgb_grid.predict_proba(np.array(test_grid_features))\n",
    "\n",
    "# Get virtual screening results on the test molecules and export results to a CSV file:\n",
    "grid_result_xgb = pd.DataFrame({\n",
    "    \"Active_Prob\": prediction_test_xgb_grid_prob[:, 0],\n",
    "    \"Inactive_Prob\": prediction_test_xgb_grid_prob[:, 1],\n",
    "    \"Predicted_Class\": prediction_test_xgb_grid_class,\n",
    "    \"Real_Class\": Test_Class\n",
    "})\n",
    "grid_result_xgb.to_csv(\"Provide_the_pathway_to_your_file_where_save_the_result_run.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11a8356-77ad-420e-a09b-d0479c39d0ad",
   "metadata": {},
   "source": [
    "## ANN ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890d1197-055e-45f4-b76f-36fb6e189c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space for optimal parameters:\n",
    "space = {\"hidden_layer_sizes\": hp.uniform(\"hidden_layer_sizes\", 8, 140),\n",
    "         \"activation\": hp.choice(\"activation\", ['relu', 'tanh']),\n",
    "         \"max_iter\": hp.uniform(\"max_iter\", 1000, 10000)}\n",
    "\n",
    "# Define the function for hyperparameter tuning:\n",
    "def hyperparameter_tuning_ANN(space):\n",
    "    model = MLPClassifier(hidden_layer_sizes = int(space['hidden_layer_sizes']),\n",
    "                          activation = space['activation'],\n",
    "                          max_iter = int(space['max_iter']))\n",
    "    model.fit(np.array(train_grid_features), Train_Class)\n",
    "    predicted_train = model.predict(np.array(train_grid_features))\n",
    "    mcc = matthews_corrcoef(Train_Class, predicted_train)\n",
    "    return {'loss': 1-mcc, 'status': STATUS_OK, 'model': model}\n",
    "    \n",
    "# Search for optimal parameters:\n",
    "trials = Trials()\n",
    "best_ann_classification = fmin(fn = hyperparameter_tuning_ANN, space = space, algo = tpe.suggest,\n",
    "                               max_evals = 10, trials = trials)\n",
    "best_params = space_eval(space, best_ann_classification)\n",
    "\n",
    "# Optimal parameters:\n",
    "best_params\n",
    "# Train the ANN model on the training molecules, using optimal parameters:\n",
    "ann_grid = MLPClassifier(hidden_layer_sizes = int(best_params['hidden_layer_sizes']), \n",
    "                         activation = best_params['activation'], \n",
    "                         max_iter = int(best_params['max_iter']), \n",
    "                         random_state = 0)\n",
    "ann_grid.fit(train_grid_features, Train_Class)\n",
    "\n",
    "# Test the ANN model on the test molecules:\n",
    "prediction_test_ann_grid_class = ann_grid.predict(test_grid_features)\n",
    "prediction_test_ann_grid_prob = ann_grid.predict_proba(test_grid_features)\n",
    "\n",
    "# Get virtual screening results on the test molecules and export results to a CSV file:\n",
    "grid_result_ann = pd.DataFrame({\"Active_Prob\": prediction_test_ann_grid_prob[:, 0],\n",
    "                                \"Inactive_Prob\": prediction_test_ann_grid_prob[:, 1],\n",
    "                                \"Predicted_Class\": prediction_test_ann_grid_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "grid_result_ann.to_csv(\"Provide_the_pathway_to_your_file_where_save_the_result_run.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464a4b9a-e4dd-4956-be4c-64fa1d598958",
   "metadata": {},
   "source": [
    "## DNN ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05ab213-e0f2-47c9-b8ff-810ff3d15453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space for optimal parameters:\n",
    "space = {'choice': hp.choice('num_layers',\n",
    "                            [ {'layers': 'two'},\n",
    "                              {'layers': 'three',\n",
    "                               'units4': hp.uniform('units4', 64, 8192), \n",
    "                               'dropout3': hp.uniform('dropout3', 0, 1)}\n",
    "                            ]),\n",
    "        'units1': hp.uniform('units1', 64, 8192),\n",
    "        'units2': hp.uniform('units2', 64, 8192),\n",
    "        'units3': hp.uniform('units3', 64, 8192),\n",
    "        'dropout1': hp.uniform('dropout1', 0, 1),\n",
    "        'dropout2': hp.uniform('dropout2', 0, 1),\n",
    "        'batch_size': hp.uniform('batch_size', 128, 500),\n",
    "        'nb_epochs': 100,\n",
    "        'optimizer': hp.choice('optimizer', ['Adadelta','Adam','rmsprop']),\n",
    "        'activation': 'relu'\n",
    "        }\n",
    "Activity_Dict = {\"Active\": 1, \"Inactive\": 0}\n",
    "y_train = [Activity_Dict[item] for item in Train_Class]\n",
    "y_test = [Activity_Dict[item] for item in Test_Class]\n",
    "y_train = np.asarray(y_train).astype(\"float32\")\n",
    "y_test = np.asarray(y_test).astype(\"float32\")\n",
    "\n",
    "# Define the function for hyperparameter tuning:\n",
    "def hyperparameter_tuning_DNN(space):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(abs(int(space['units1'])), kernel_regularizer = regularizers.l2(0.001), activation = \"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(space['dropout1']),\n",
    "        layers.Dense(abs(int(space['units2'])), kernel_regularizer = regularizers.l2(0.001), activation = \"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(abs(int(space['units3'])), kernel_regularizer = regularizers.l2(0.001), activation = \"relu\"),\n",
    "        layers.Dropout(space['dropout2']),\n",
    "        layers.Dense(1, activation = \"sigmoid\")\n",
    "    ])\n",
    "    model.compile(optimizer = 'adam', loss = \"binary_crossentropy\", metrics = ['accuracy'])\n",
    "    model.fit(np.array(train_grid_features), y_train, epochs = 100, batch_size = int(space['batch_size']), verbose = False)\n",
    "    predict_proba = model.predict(np.array(train_grid_features))[:, 0]\n",
    "    predicted_train = ['Active' if num >= 0.5 else \"Inactive\" for num in predict_proba]\n",
    "    # Calculate Matthews Correlation Coefficient\n",
    "    mcc = matthews_corrcoef(Train_Class, predicted_train)\n",
    "    \n",
    "    return {'loss': 1-mcc, 'status': STATUS_OK, 'model': model, 'MCC': mcc}\n",
    "\n",
    "# Search for optimal parameters:\n",
    "trials = Trials()\n",
    "best_dnn_classification = fmin(hyperparameter_tuning_DNN, space, algo = tpe.suggest, \n",
    "                               max_evals = 10, trials = trials)\n",
    "best_params = space_eval(space, best_dnn_classification)\n",
    "\n",
    "# Optimal parameters:\n",
    "best_params\n",
    "# Save AUC and MCC of best model to a CSV\n",
    "results = pd.DataFrame({'Best Parameters': [best_params], 'MCC': [trials.best_trial['result']['MCC']]})\n",
    "results.to_csv(\"best_model_results.csv\", index=False)\n",
    "# Train the DNN model on the training molecules using optimal parameters:\n",
    "tf.random.set_seed(0)\n",
    "dnn_grid = keras.Sequential([\n",
    "    layers.Dense(units = int(best_params['units1']), kernel_regularizer = regularizers.l2(0.001), activation = \"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(best_params['dropout1']),\n",
    "    layers.Dense(units = int(best_params['units2']), kernel_regularizer = regularizers.l2(0.001), activation = \"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(units = int(best_params['units3']), kernel_regularizer = regularizers.l2(0.001), activation = \"relu\"),\n",
    "    layers.Dropout(best_params['dropout2']),\n",
    "    layers.Dense(1, activation = \"sigmoid\")    \n",
    "])\n",
    "dnn_grid.compile(optimizer = best_params['optimizer'], loss = \"binary_crossentropy\", metrics = ['accuracy'])\n",
    "dnn_grid.fit(np.array(train_grid_features), y_train, epochs = 100, \n",
    "             batch_size = int(best_params['batch_size']), verbose = False)\n",
    "\n",
    "# Test the DNN model on the test molecules:\n",
    "prediction_test_dnn_grid_prob = dnn_grid.predict(np.array(test_grid_features))\n",
    "prediction_test_dnn_grid_class = ['Active' if num >= 0.5 else \"Inactive\" for num in prediction_test_dnn_grid_prob]\n",
    "\n",
    "# Get virtual screening results on the test molecules and export results to a CSV file:\n",
    "grid_result_dnn = pd.DataFrame({\"Active_Prob\": prediction_test_dnn_grid_prob[:, 0],\n",
    "                                \"Predicted_Class\": prediction_test_dnn_grid_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "grid_result_dnn.to_csv(\"Provide_the_pathway_to_your_file_where_save_the_result_run.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
